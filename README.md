# â˜ï¸ Cloud Computing RAG System using Ollama + LangChain

## ğŸ‘©â€ğŸ“ Student Details

**Name:** Supriya Nanekar
**Subject:** Cloud Computing
**Project Type:** AI-based Study Assistant

---

## ğŸ“Œ Project Overview

This project is an **AI-powered Cloud Computing Assistant** that answers user questions based on a given PDF (study material).

The system uses **RAG (Retrieval Augmented Generation)** to retrieve relevant content from documents and generate accurate answers using a **local LLM (Ollama - phi3 model)**.

---

## ğŸ¯ Objective

The main objective of this project is to:

* Convert cloud computing notes into a searchable knowledge base
* Retrieve relevant information based on user queries
* Generate accurate and meaningful answers using AI

---

## ğŸ› ï¸ Technologies Used

* Python
* LangChain
* ChromaDB (Vector Database)
* HuggingFace Embeddings
* Ollama (phi3 model - local LLM)
* PyPDF Loader
* NLTK

---

## ğŸ” System Workflow

1. Load PDF using PyPDFLoader
2. Split document into smaller chunks
3. Convert text into vector embeddings
4. Store embeddings in ChromaDB
5. Retrieve similar chunks using similarity search
6. Send retrieved context to Ollama LLM
7. Generate final answer

---

## ğŸ§  What is RAG?

**RAG (Retrieval Augmented Generation)** is a technique that combines:

* **Retrieval** â†’ searching relevant information from documents
* **Generation** â†’ generating answers using a language model

This improves accuracy and ensures answers are based on real data.

---

## ğŸ“‚ Project Structure

```
cloud-computing-rag-system/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ cloud1.pdf
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Cloud_RAG_Assistant.ipynb
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone Repository

```
git clone https://github.com/Nanekar123/cloud-computing-rag-system.git
cd cloud-computing-rag-system
```

### 2ï¸âƒ£ Install Dependencies

```
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run Ollama Model

```
ollama run phi3
```

### 4ï¸âƒ£ Launch Notebook

```
jupyter notebook
```

Open:

```
notebooks/Cloud_RAG_Assistant.ipynb
```

---

## ğŸ§ª Sample Questions Tested

* What is cloud computing?
* Explain IaaS, PaaS, SaaS
* What is virtualization?
* Explain public cloud and private cloud
* What is scalability in cloud computing?
* Explain elasticity in cloud computing

---

## ğŸ“ˆ Output

The system generates answers based only on the provided PDF data, ensuring **accuracy and relevance**.

---

## âœ… Advantages

* Works completely offline using Ollama
* No API cost required
* Accurate answers from study material
* Useful for exam preparation

---

## âš ï¸ Limitations

* Answers only from uploaded PDF
* Requires local setup
* Depends on quality of input data

---

## ğŸš€ Future Improvements

* Add web interface using Streamlit
* Support multiple PDFs
* Add voice input
* Deploy on cloud

---

## ğŸ™ Conclusion

This project demonstrates how **Cloud Computing concepts** can be integrated with **AI and RAG architecture** to build an intelligent study assistant.

---

## ğŸ“š Acknowledgement

This project is developed as part of **Cloud Computing Academic Assignment**.
