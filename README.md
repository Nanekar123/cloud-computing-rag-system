ğŸ“˜ Cloud Computing RAG System
Retrieval-Augmented Generation using Ollama + FAISS
ğŸ‘©â€ğŸ’» Author

Supriya Nanekar
AI/ML Assignment â€“ Retrieval-Augmented Generation (RAG)

ğŸ“Œ Project Overview

This project implements a Retrieval-Augmented Generation (RAG) system to answer questions based on a Cloud Computing PDF (110 pages).

The system retrieves relevant information from the document using semantic search and generates accurate answers using a local Large Language Model (LLM) powered by Ollama (Llama3).

This project demonstrates practical understanding of:

Retrieval-Augmented Generation (RAG)

Vector Databases (FAISS)

Embeddings

Prompt Engineering

Local LLM Deployment

Model Evaluation

ğŸ¯ Objective

To build a question-answering system that:

Uses Cloud Computing notes as a knowledge base

Retrieves relevant content using vector similarity

Generates context-aware answers

Minimizes hallucination

Works completely offline

ğŸ“‚ Dataset

File Name: CloudComputingNotes.pdf

Pages: 110

Type: Text-based academic notes

Domain: Cloud Computing

Topics Covered:

Cloud Computing Basics

Service Models (IaaS, PaaS, SaaS)

Deployment Models

Virtualization

Elasticity

Load Balancing

Security Challenges

Multi-tenancy

ğŸ—ï¸ System Architecture

PDF
â†“
Text Extraction
â†“
Text Chunking
â†“
Embedding Generation
â†“
FAISS Vector Store
â†“
Retriever (Top-K Similarity Search)
â†“
Ollama (Llama3 LLM)
â†“
Generated Answer

ğŸ› ï¸ Technologies Used

Python

LangChain

Ollama (Local LLM)

FAISS (Vector Database)

Sentence Transformers

PyPDF

âš™ï¸ Installation & Setup
1ï¸âƒ£ Install Required Libraries
pip install langchain
pip install langchain-community
pip install sentence-transformers
pip install faiss-cpu
pip install pypdf
2ï¸âƒ£ Install Ollama

Download Ollama from:

https://ollama.com

Pull the model:

ollama pull llama3

Run the model:

ollama run llama3

Keep Ollama running in the background.

ğŸš€ How to Run the Project

Clone this repository

Place CloudComputingNotes.pdf inside the project folder

Open the Jupyter Notebook

Run all cells sequentially

The system will:

Extract text from the PDF

Create text chunks

Generate embeddings

Build FAISS vector store

Retrieve relevant content

Generate answers using Ollama

ğŸ“Š Evaluation

The system was tested using 12 Cloud Computing questions.

Evaluation Criteria

Relevance (5)

Completeness (5)

Hallucination Check (5)

â­ Average Score: 13.4 / 15
ğŸ” Improvements Implemented

Increased chunk size (800)

Added chunk overlap (150)

Increased retriever k value

Improved prompt structure

Structured answer formatting

ğŸ“ˆ Baseline vs Improved System
Metric	Baseline	Improved
Retrieval Accuracy	Medium	High
Completeness	Medium	High
Hallucination	Low	Very Low
Average Score	12.1	13.4
âœ… Key Features

âœ” Fully Offline (No OpenAI API required)
âœ” Semantic Search using FAISS
âœ” Context-based Answer Generation
âœ” Reduced Hallucination
âœ” Academic Evaluation Included

ğŸ“ Repository Structure
cloud-rag-project/
â”‚
â”œâ”€â”€ CloudComputingNotes.pdf
â”œâ”€â”€ rag_notebook.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
ğŸ Conclusion

The implemented RAG system successfully retrieves and generates accurate answers from Cloud Computing notes. The improved version demonstrates better retrieval quality, improved completeness, and minimal hallucination.

This project showcases practical implementation of modern AI retrieval systems using open-source tools and local LLMs.